Personalized Movie Recommendation System

# 1. Imports

import pandas as pd

import numpy as np

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error

from surprise import Dataset, Reader, SVD

from surprise.model_selection import cross_validate

import matplotlib.pyplot as plt

import seaborn as sns

# 2. Data Collection & Preprocessing

ratings = pd.read_csv('ratings.csv')  # e.g., userId, movieId, rating, timestamp

movies = pd.read_csv('movies.csv')    # e.g., movieId, title, genres

# Merge datasets

data = pd.merge(ratings, movies, on='movieId')

# 3. EDA (Exploratory Data Analysis)

plt.figure(figsize=(10, 4))

data['rating'].value_counts().sort_index().plot(kind='bar')

plt.title('Rating Distribution')

plt.xlabel('Rating')

plt.ylabel('Frequency')

plt.show()

# Top genres

movies['genres'] = movies['genres'].str.split('|')

all_genres = movies.explode('genres')

plt.figure(figsize=(12, 5))

all_genres['genres'].value_counts().plot(kind='bar')

plt.title('Genre Distribution')

plt.show()

# 4. Feature Engineering

# Use Surprise library (which handles encoding internally)

reader = Reader(rating_scale=(0.5, 5.0))

data_surprise = Dataset.load_from_df(data[['userId', 'movieId', 'rating']], reader)

# 5. Model Building - SVD (Collaborative Filtering)

model = SVD()

cross_validate(model, data_surprise, measures=['RMSE', 'MAE'], cv=5, verbose=True)

# 6. Model Evaluation (Train-Test Split)

trainset, testset = train_test_split(data_surprise.build_full_trainset().build_testset(), test_size=0.2)

model.fit(data_surprise.build_full_trainset())

predictions = model.test(testset)

# Calculate RMSE

pred_ratings = np.array([pred.est for pred in predictions])

true_ratings = np.array([pred.r_ui for pred in predictions])

rmse = np.sqrt(mean_squared_error(true_ratings, pred_ratings))

print(f"Test RMSE: {rmse:.4f}")

# 7. Visualization of Model Insights

# Show 10 recommendations for a sample user

from collections import defaultdict

def get_top_n(predictions, n=10):

   top_n = defaultdict(list)

   for uid, iid, true_r, est, _ in predictions:

       top_n[uid].append((iid, est))

   for uid, user_ratings in top_n.items():

       user_ratings.sort(key=lambda x: x[1], reverse=True)

       top_n[uid] = user_ratings[:n]

   return top_n

# Get top 10 recommendations for user 1

top_n = get_top_n(predictions, n=10)

print("Top 10 Recommendations for User 1:")

print(top_n[1])

# 8. Deployment (Simplified API via FastAPI)

# pip install fastapi uvicorn

# Save model and create endpoint

from fastapi import FastAPI

import pickle

# Save model

with open('svd_model.pkl', 'wb') as f:

   pickle.dump(model, f)

# FastAPI app

app = FastAPI()

@app.get("/recommend/{user_id}")

def recommend_movies(user_id: int, n: int = 10):

   with open('svd_model.pkl', 'rb') as f:

       model = pickle.load(f)

   movie_ids = data['movieId'].unique()

   predictions = [(mid, model.predict(user_id, mid).est) for mid in movie_ids]

   predictions.sort(key=lambda x: x[1], reverse=True)

   recommended_ids = [mid for mid, _ in predictions[:n]]

   recommended_movies = movies[movies['movieId'].isin(recommended_ids)]

   return recommended_movies[['title', 'genres']].to_dict(orient='records')
